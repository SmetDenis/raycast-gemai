---
description:
globs:
alwaysApply: false
---
# Паттерны реализации AI провайдеров

## Универсальная система провайдеров
- **ВСЕГДА используй `buildAIConfig()`** вместо `buildGemAIConfig()` для нового кода
- `AIConfig` - универсальный интерфейс, `GemAIConfig` только для обратной совместимости
- Автоопределение провайдера на базе выбранной модели в `@buildAIConfig.ts`
- Паттерн фабрики: `createAIProvider(config)` возвращает подходящий провайдер

## Reasoning модели (o1-серия) - КРИТИЧНО!
- **НИКОГДА** не отправляй system prompts как отдельные сообщения в o1-preview/o1-mini
- **ВСЕГДА** включай system prompt в user message для reasoning моделей
- Используй `max_completion_tokens` вместо `max_tokens` для o1-серии
- Фиксированная температура = 1 для reasoning моделей (требование OpenAI)

## Vision API и автопереключение
- **Reasoning модели НЕ поддерживают vision** - автопереключение o1 → GPT-4o при обнаружении изображения
- Показывай пользователю уведомление об автопереключении модели
- Сохраняй исходные настройки конфига при переключении

## Подсчет токенов и статистика
- Используй реальные данные использования API (`usageMetadata`) когда доступно
- OpenAI: `prompt_tokens` включает system + user, вычисляй user токены вычитанием
- Gemini: `promptTokenCount` = весь ввод, `candidatesTokenCount` = выходные токены
- Включай thinking токены для reasoning моделей в статистику

## Обработка файлов и вложений
- Для текстовых файлов: читай как текст через `fs.readFileSync(file, 'utf8')`
- Для изображений: используй `provider.prepareAttachment()`
- Обрабатывай MIME типы не поддерживаемые API провайдерами
- Двухуровневая стратегия: текст → API fallback

## Паттерн универсального провайдера
```typescript
// ✅ Создание провайдера
const config = buildAIConfig(actionName, props);
const provider = createAIProvider(config);

// ✅ Использование с fallback
try {
  const result = await provider.method(config, data);
} catch (error) {
  // Обработка специфичных ошибок провайдера
}
```
