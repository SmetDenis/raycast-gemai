# Raycast GemAI - Legacy Rules (DEPRECATED - Use .cursor/rules/*.mdc)

⚠️ **DEPRECATED**: This `.cursorrules` file is legacy. 
✅ **USE INSTEAD**: Modern `.cursor/rules/*.mdc` files for better organization and token efficiency.

## Quick Reference for Modern Rules

The new rule system provides better organization and context-aware activation:

- **001-workspace.mdc**: Core project architecture and universal provider system
- **002-cursor-rules.mdc**: How .mdc files work and best practices  
- **100-typescript-raycast.mdc**: TypeScript and Raycast development standards
- **200-ai-provider-patterns.mdc**: AI provider implementation patterns
- **201-models-pricing.mdc**: Model definitions and pricing management
- **202-debugging-troubleshooting.mdc**: Debugging strategies and common issues
- **203-screenshot-vision.mdc**: Screenshot processing and vision API integration

## Critical Points (Legacy Compatibility)

### Universal Provider System
- Use `buildAIConfig()` instead of `buildGemAIConfig()` for new code
- `AIConfig` is universal interface, `GemAIConfig` for backward compatibility
- Provider auto-detection based on model selection
- Factory pattern: `createAIProvider(config)` returns appropriate provider

### Reasoning Models (o1-series)
- NEVER send system prompts as separate messages to o1-preview/o1-mini
- ALWAYS include system prompt in user message for reasoning models
- Use `max_completion_tokens` instead of `max_tokens` for o1-series
- Fixed temperature = 1 for reasoning models (OpenAI requirement)

### Vision API Auto-switching  
- Reasoning models don't support vision - auto-switch to GPT-4o when image detected
- Show user notification about model auto-switching
- Preserve original config settings when switching

### Debug Logging
- Production: All debug `console.log()` should be commented out
- Keep error handling: `console.error()` for genuine errors should remain
- Comment Format: Use `// console.log(...)` to preserve debugging code

**This is a production Raycast extension used by real users. Prioritize stability, clear user feedback, and smooth operation across all supported AI models.** 